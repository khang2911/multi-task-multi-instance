{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"edges\": [[0, 1],[1, 2],[2, 3],[3, 4]],\n",
    " \"labels\": {\"0\": \"A\", \"1\": \"B\", \"2\": \"C\", \"3\": \"A\", \"4\": \"B\"},\n",
    " \"target\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = os.listdir('./data/NCI_txt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MCF-7',\n",
       " 'MOLT-4',\n",
       " 'NCI-H23',\n",
       " 'OVCAR-8',\n",
       " 'PC-3',\n",
       " 'SF-295',\n",
       " 'SN12C',\n",
       " 'SW-620',\n",
       " 'UACC257']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks.remove('P388')\n",
    "tasks.remove('Yeast')\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MCF-7 - 27770 graphs\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "MCF-7 done\n",
      "Remain graphs: 26754\n",
      "\n",
      "Processing MOLT-4 - 39765 graphs\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "MOLT-4 done\n",
      "Remain graphs: 25488\n",
      "\n",
      "Processing NCI-H23 - 40353 graphs\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "NCI-H23 done\n",
      "Remain graphs: 24700\n",
      "\n",
      "Processing OVCAR-8 - 40516 graphs\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "OVCAR-8 done\n",
      "Remain graphs: 24117\n",
      "\n",
      "Processing PC-3 - 27509 graphs\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "PC-3 done\n",
      "Remain graphs: 22857\n",
      "\n",
      "Processing SF-295 - 40271 graphs\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "SF-295 done\n",
      "Remain graphs: 22386\n",
      "\n",
      "Processing SN12C - 40004 graphs\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "SN12C done\n",
      "Remain graphs: 21596\n",
      "\n",
      "Processing SW-620 - 40532 graphs\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "SW-620 done\n",
      "Remain graphs: 21071\n",
      "\n",
      "Processing UACC257 - 39988 graphs\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "UACC257 done\n",
      "Remain graphs: 20527\n",
      "\n",
      "Time: 13834.687901258469\n"
     ]
    }
   ],
   "source": [
    "meta_data = {}\n",
    "first_loop = 0\n",
    "begin = time.time()\n",
    "\n",
    "##########\n",
    "for task in tasks:\n",
    "    ##########\n",
    "    edges_raw = open('./data/NCI_txt/%s/%s_A.txt'%(task,task)).read().split('\\n')[:-1]\n",
    "    graph_ID_of_nodes = open('./data/NCI_txt/%s/%s_graph_indicator.txt'%(task,task)).read().split('\\n')[:-1]\n",
    "    node_labels_raw = open('./data/NCI_txt/%s/%s_node_labels_multitask.txt'%(task,task)).read().split('\\n')[:-1]\n",
    "    graph_labels_raw = open('./data/NCI_txt/%s/%s_graph_labels.txt'%(task,task)).read().split('\\n')[:-1]\n",
    "    \n",
    "    ##########\n",
    "    track = 0\n",
    "    duplicate_bin = []\n",
    "    start_node = 0\n",
    "    start_edge = 0\n",
    "    print('Processing %s - %s graphs'%(task,len(graph_labels_raw)))\n",
    "    ##########\n",
    "    for i in graph_labels_raw :\n",
    "        ###### Add graph target\n",
    "        data = {}\n",
    "        data['target%s'%tasks.index(task)] = int(i)\n",
    "\n",
    "        ######\n",
    "        try:\n",
    "            num_nodes = graph_ID_of_nodes.index(str(track+2)) - start_node\n",
    "        except:\n",
    "            num_nodes = len(graph_ID_of_nodes) - int(graph_ID_of_nodes.index(str(track+1)))\n",
    "\n",
    "        ######\n",
    "        nodes_labels = node_labels_raw[start_node:num_nodes+start_node]\n",
    "        \n",
    "\n",
    "        ###### Add node labels\n",
    "        data['labels'] = {'0':nodes_labels[0]}\n",
    "        nodes_identifier = 1\n",
    "        for label in nodes_labels[1:]:\n",
    "            data['labels'][str(nodes_identifier)] = label\n",
    "            nodes_identifier+=1\n",
    "\n",
    "        ###### Add edges\n",
    "        edges = []\n",
    "\n",
    "        for pair in edges_raw[start_edge:]:\n",
    "            last = int(pair.split(',')[-1])\n",
    "            first = int(pair.split(',')[0])\n",
    "\n",
    "            if last <= (start_node+num_nodes):\n",
    "                first = first - start_node -1\n",
    "                last = last - start_node -1\n",
    "                edges.append([first,last])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        data['edges'] = edges\n",
    "        \n",
    "        compound = [tuple(i) for i in edges]\n",
    "        compound = hash(tuple(compound))\n",
    "        \n",
    "        \n",
    "        ####### update tracking\n",
    "        start_node+=num_nodes\n",
    "        start_edge+=len(edges)\n",
    "        track+=1\n",
    "        #######\n",
    "        if track % 5000 == 0:\n",
    "            print(track)\n",
    "            \n",
    "        ######\n",
    "        if compound not in duplicate_bin:\n",
    "            if compound not in meta_data and first_loop == 0:\n",
    "                meta_data[compound] = [data]\n",
    "            elif compound not in meta_data and first_loop == 1:\n",
    "                pass\n",
    "            else:\n",
    "                meta_data[compound].append(data)\n",
    "        else:\n",
    "            if compound in meta_data:\n",
    "                del meta_data[compound]\n",
    "        \n",
    "        #####\n",
    "        duplicate_bin.append(compound)\n",
    "        \n",
    "    #######\n",
    "    if tasks.index(task) != 0 :\n",
    "        for each in list(meta_data):\n",
    "            if len(meta_data[each]) < (tasks.index(task) + 1):\n",
    "                del meta_data[each]\n",
    "    #######\n",
    "    first_loop = 1\n",
    "    print('%s done'%task)\n",
    "    print('Remain graphs: %s\\n'%len(meta_data))\n",
    "\n",
    "\n",
    "\n",
    "###########\n",
    "outdir = './data/input/train/'\n",
    "track = 0\n",
    "\n",
    "for each in meta_data:\n",
    "    #######\n",
    "    data = meta_data[each][0]\n",
    "    \n",
    "    #######\n",
    "    for i in range(len(meta_data[each])):\n",
    "        data['target%s'%i] = meta_data[each][i]['target%s'%i]\n",
    "    \n",
    "    #######\n",
    "    ####### Save file\n",
    "    outfile = open(os.path.join(outdir,os.path.basename('graph_%s.json'%track)),'w')\n",
    "    outfile.write(json.dumps(data))  \n",
    "    outfile.close()\n",
    "    #######\n",
    "    track+=1\n",
    "\n",
    "\n",
    "        \n",
    "print('Time: %s'%(time.time()-begin))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = os.listdir('./data/input/train_full/')\n",
    "graphs = []\n",
    "for each in data:\n",
    "    graphs.append(json.loads(open('./data/input/train_full/%s'%each).read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "sample = []\n",
    "count = 0\n",
    "track = 0\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "ID = [i for i in range(len(graphs))]\n",
    "random.shuffle(ID)\n",
    "\n",
    "for i in ID:\n",
    "    if graphs[i]['target1'] == 1:\n",
    "        sample.append(graphs[i])\n",
    "        X.append(track)\n",
    "        y.append(graphs[i]['target1'])\n",
    "        track+=1\n",
    "        \n",
    "for i in ID:\n",
    "    if graphs[i]['target1'] == 0:\n",
    "        sample.append(graphs[i])\n",
    "        X.append(track)\n",
    "        y.append(graphs[i]['target1'])\n",
    "        track+=1\n",
    "        count+= 1\n",
    "    if count > 2100 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "track = 0\n",
    "\n",
    "for each in X_train:\n",
    "    #######\n",
    "    data = sample[each]\n",
    "    outdir = './data/input/train/'\n",
    "    \n",
    "    #######\n",
    "    ####### Save file\n",
    "    outfile = open(os.path.join(outdir,os.path.basename('graph_%s.json'%track)),'w')\n",
    "    outfile.write(json.dumps(data))  \n",
    "    outfile.close()\n",
    "    #######\n",
    "    track+=1\n",
    "\n",
    "for each in X_test:\n",
    "    #######\n",
    "    data = sample[each]\n",
    "    outdir = './data/input/test/'\n",
    "    \n",
    "    #######\n",
    "    ####### Save file\n",
    "    outfile = open(os.path.join(outdir,os.path.basename('graph_%s.json'%track)),'w')\n",
    "    outfile.write(json.dumps(data))  \n",
    "    outfile.close()\n",
    "    #######\n",
    "    track+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
